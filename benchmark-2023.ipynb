{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00ffee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, ConfusionMatrixDisplay, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d450abe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T10:55:58.780575Z",
     "iopub.status.busy": "2023-03-31T10:55:58.780166Z",
     "iopub.status.idle": "2023-03-31T10:55:58.992240Z",
     "shell.execute_reply": "2023-03-31T10:55:58.991225Z"
    },
    "papermill": {
     "duration": 0.219589,
     "end_time": "2023-03-31T10:55:58.994949",
     "exception": false,
     "start_time": "2023-03-31T10:55:58.775360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load training dataset, remove missing values in Y, create X and Y matrices.\n",
    "\n",
    "df_train = pd.read_csv('data/train.csv')\n",
    "\n",
    "df_train.dropna(subset=['Y'], inplace=True)\n",
    "\n",
    "X = df_train.drop('Y', axis = 1)\n",
    "y = df_train[['Y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.8, test_size=0.2, shuffle=True, random_state=0\n",
    ")\n",
    "\n",
    "#Load test predictors\n",
    "\n",
    "X_test_real = pd.read_csv('data/Xtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e45e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_grid_params = dict(cv=5, n_jobs=4, verbose=0, scoring='neg_log_loss')\n",
    "\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [100], # 3, 5, 7, 10, 14, 20, 50, 100, 200, 500, 1000\n",
    "    'weights': ['distance'], # 'uniform'\n",
    "    'p': [1], # 2\n",
    "}\n",
    "\n",
    "param_grid_lr = {\n",
    "    'penalty': ['l2'],\n",
    "    'C': [100, 1000], # 0.001, 0.01, 0.1, 1, 10, \n",
    "    'fit_intercept': [True], # False\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [ 1000, 2000, 4000], # 1000\n",
    "    'criterion' : [\"log_loss\"],\n",
    "    \"max_depth\" : [ 50, 100, 300, 500], # 100\n",
    "    'min_samples_split' : [2, 5], # 2\n",
    "    'min_samples_leaf' : [1, 2] # 1\n",
    "}\n",
    "\n",
    "param_grid_gb = {\n",
    "    'loss': ['log_loss'],\n",
    "    'learning_rate': [0.02, 0.1, 0.5], # 0.1, 0.5\n",
    "    'n_estimators': [300, 500, 750, 1000], # 100, 200 \n",
    "    'criterion': ['squared_error'],\n",
    "    'max_depth': [None, 2, 5, 10], # None, 2, 10\n",
    "    'validation_fraction' : [0.2],\n",
    "    'n_iter_no_change' : [5],\n",
    "    'tol' : [1e-4]\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50a12efa",
   "metadata": {},
   "source": [
    "## Pipeline for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a538f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sub, X_train_sub, X_test_sub):\n",
    "    numeric_features = copy.copy(sub)\n",
    "    categorical_features = list()\n",
    "    if \"X11\" in sub:\n",
    "        numeric_features.remove(\"X11\")\n",
    "        categorical_features.append(\"X11\")\n",
    "    if \"X12\" in sub:\n",
    "        numeric_features.remove(\"X12\")\n",
    "        categorical_features.append(\"X12\")\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')), # mean, median, most_frequent\n",
    "        ('scaler', StandardScaler())])\n",
    "\n",
    "    if len(categorical_features) > 1:\n",
    "        X_train_sub = X_train_sub.astype({'X11':'category', 'X12':'category'})\n",
    "        X_test_sub = X_test_sub.astype({'X11':'category', 'X12':'category'})\n",
    "    elif len(categorical_features) == 1:\n",
    "        if categorical_features[0] == \"X11\":\n",
    "            X_train_sub = X_train_sub.astype({'X11':'category'})\n",
    "            X_test_sub = X_test_sub.astype({'X11':'category'})\n",
    "        else:\n",
    "            X_train_sub = X_train_sub.astype({'X12':'category'})\n",
    "            X_test_sub = X_test_sub.astype({'X12':'category'})\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')), # obligatoire\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first'))]) #Same as pd.get_dummies \n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)])\n",
    "    \n",
    "    return preprocessor, X_train_sub, X_test_sub"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46d02352",
   "metadata": {},
   "source": [
    "### Permet de vérifier si les colonnes trouvés par la correlation sont bien les mêmes que celles trouvés par combinaison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcad47a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T10:55:59.000812Z",
     "iopub.status.busy": "2023-03-31T10:55:59.000181Z",
     "iopub.status.idle": "2023-03-31T10:56:05.547158Z",
     "shell.execute_reply": "2023-03-31T10:56:05.545355Z"
    },
    "papermill": {
     "duration": 6.556451,
     "end_time": "2023-03-31T10:56:05.553525",
     "exception": false,
     "start_time": "2023-03-31T10:55:58.997074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Select predictors, apply pre-processing steps, define the model, and fit the model to the training data.\n",
    "dict = {}\n",
    "for i in range(1, 13):\n",
    "    liste = list(itertools.combinations(X_train.columns, i))\n",
    "    for sub in liste:\n",
    "        sub = list(sub)\n",
    "        X_train_sub  = X_train[sub]\n",
    "        X_test_sub = X_test[sub]\n",
    "\n",
    "        preprocessor, X_train_sub, X_test_sub = preprocessing(sub, X_train_sub, X_test_sub)\n",
    "\n",
    "        grids = {'KNN': GridSearchCV(KNeighborsClassifier(), param_grid_knn, **default_grid_params)}\n",
    "\n",
    "        model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', grids[\"KNN\"])])\n",
    "        model.fit(X_train_sub, y_train.values.ravel())\n",
    "        grids[\"KNN\"] = model\n",
    "        print(\"KNN fitted\")\n",
    "        pred_prob_train = pd.DataFrame(model.predict_proba(X_test_sub))\n",
    "        loss = log_loss(y_test, pred_prob_train)\n",
    "        print(f'KNN : {loss} for {sub}')\n",
    "        dict[(i, tuple(sub))] = loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ee7c32a",
   "metadata": {},
   "source": [
    "### Code générique pour construire notre model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "367d357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit all models \n",
    "sub = [\"X1\", \"X6\", \"X10\", \"X11\", \"X12\"]\n",
    "X_train_sub  = X_train[sub]\n",
    "X_test_sub = X_test[sub]\n",
    "\n",
    "preprocessor, X_train_sub, X_test_sub = preprocessing(sub, X_train_sub, X_test_sub)\n",
    "\n",
    "grids = {'KNN': GridSearchCV(KNeighborsClassifier(), param_grid_knn, **default_grid_params),\n",
    "        'Logistic Regression': GridSearchCV(LogisticRegression(max_iter=1000), param_grid_lr, **default_grid_params),\n",
    "        'Random Forest': GridSearchCV(ExtraTreesClassifier(), param_grid_rf, **default_grid_params),\n",
    "        'Gradient Boosting': GridSearchCV(GradientBoostingClassifier(), param_grid_gb, **default_grid_params)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f45f54ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest fitted\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m model_name, model \u001b[39min\u001b[39;00m grids\u001b[39m.\u001b[39mitems():\n\u001b[0;32m      2\u001b[0m     model \u001b[39m=\u001b[39m Pipeline(steps\u001b[39m=\u001b[39m[(\u001b[39m'\u001b[39m\u001b[39mpreprocessor\u001b[39m\u001b[39m'\u001b[39m, preprocessor),\n\u001b[0;32m      3\u001b[0m                       (\u001b[39m'\u001b[39m\u001b[39mclassifier\u001b[39m\u001b[39m'\u001b[39m, model)])\n\u001b[1;32m----> 4\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train_sub, y_train\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39;49mravel())\n\u001b[0;32m      5\u001b[0m     grids[model_name] \u001b[39m=\u001b[39m model\n\u001b[0;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m fitted\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\benoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    404\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 405\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[0;32m    407\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\benoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\benoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\benoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\benoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\benoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\benoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\benoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\benoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\benoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for model_name, model in grids.items():\n",
    "    model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', model)])\n",
    "    model.fit(X_train_sub, y_train.values.ravel())\n",
    "    grids[model_name] = model\n",
    "    print(f'{model_name} fitted')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e748e8ba",
   "metadata": {},
   "source": [
    "## Compute the predicted probability for each class on the training set and evaluate on the log-loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca3643bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss on training set...\n",
      "Random Forest: 0.33469724616722873\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m log_loss_test \u001b[39m=\u001b[39m {}\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m model_name, model \u001b[39min\u001b[39;00m grids\u001b[39m.\u001b[39mitems():\n\u001b[1;32m----> 4\u001b[0m     pred_prob_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(model\u001b[39m.\u001b[39;49mpredict_proba(X_test_sub))\n\u001b[0;32m      5\u001b[0m     loss \u001b[39m=\u001b[39m log_loss(y_test, pred_prob_train)\n\u001b[0;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\benoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:521\u001b[0m, in \u001b[0;36mBaseSearchCV.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[39m@available_if\u001b[39m(_estimator_has(\u001b[39m\"\u001b[39m\u001b[39mpredict_proba\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m    502\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_proba\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    503\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Call predict_proba on the estimator with the best found parameters.\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \n\u001b[0;32m    505\u001b[0m \u001b[39m    Only available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[39m        to that in the fitted attribute :term:`classes_`.\u001b[39;00m\n\u001b[0;32m    520\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 521\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    522\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mpredict_proba(X)\n",
      "File \u001b[1;32mc:\\Users\\benoi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1390\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1385\u001b[0m     fitted \u001b[39m=\u001b[39m [\n\u001b[0;32m   1386\u001b[0m         v \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m \u001b[39mvars\u001b[39m(estimator) \u001b[39mif\u001b[39;00m v\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m v\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1387\u001b[0m     ]\n\u001b[0;32m   1389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fitted:\n\u001b[1;32m-> 1390\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(msg \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(estimator)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "print(\"Log-loss on training set...\")\n",
    "log_loss_test = {}\n",
    "for model_name, model in grids.items():\n",
    "    pred_prob_train = pd.DataFrame(model.predict_proba(X_test_sub))\n",
    "    loss = log_loss(y_test, pred_prob_train)\n",
    "    print(f'{model_name}: {loss}')\n",
    "    log_loss_test[model_name] = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44610bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model compare by the log-loss on the test set.\n",
    "best_model = min(dict, key=dict.get)\n",
    "print(f'Best model is {best_model} with a log-loss of {dict[best_model]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b56362c2",
   "metadata": {},
   "source": [
    "## Predict on the test predictors, and save the probabilities to a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016a0932",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_test = pd.DataFrame(grids[best_model].predict_proba(X_test_real))\n",
    "pred_prob_test.rename(columns = {0: 'Y_1', 1: 'Y_2', 2: 'Y_3', 3: 'Y_4', 4: 'Y_5', 5:'Y_6', 6:'Y_7'}, inplace = True)\n",
    "idx = pred_prob_test.index\n",
    "pred_prob_test.insert(0, 'id', idx)\n",
    "pred_prob_test.to_csv(\"Group13.csv\", index=False)\n",
    "pred_prob_test.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e25b73df",
   "metadata": {},
   "source": [
    "https://askcodez.com/comment-ameliorer-randomforest-la-performance.html\n",
    "\n",
    "https://stats.stackexchange.com/questions/53240/practical-questions-on-tuning-random-forests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.826631,
   "end_time": "2023-03-31T10:56:08.679002",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-31T10:55:47.852371",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
