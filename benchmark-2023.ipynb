{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00ffee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, ConfusionMatrixDisplay, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d450abe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T10:55:58.780575Z",
     "iopub.status.busy": "2023-03-31T10:55:58.780166Z",
     "iopub.status.idle": "2023-03-31T10:55:58.992240Z",
     "shell.execute_reply": "2023-03-31T10:55:58.991225Z"
    },
    "papermill": {
     "duration": 0.219589,
     "end_time": "2023-03-31T10:55:58.994949",
     "exception": false,
     "start_time": "2023-03-31T10:55:58.775360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load training dataset, remove missing values in Y, create X and Y matrices.\n",
    "\n",
    "df_train = pd.read_csv('data/train.csv')\n",
    "\n",
    "df_train.dropna(subset=['Y'], inplace=True)\n",
    "\n",
    "X = df_train.drop('Y', axis = 1)\n",
    "y = df_train[['Y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.8, test_size=0.2, shuffle=True, random_state=0\n",
    ")\n",
    "\n",
    "#Load test predictors\n",
    "\n",
    "X_test_real = pd.read_csv('data/Xtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e45e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_grid_params = dict(cv=5, n_jobs=4)\n",
    "\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [100], # 3, 5, 7, 10, 14, 20, 50, 100, 200, 500, 1000\n",
    "    'weights': ['distance'], # 'uniform'\n",
    "    'p': [1], # 2\n",
    "}\n",
    "\n",
    "param_grid_lr = {\n",
    "    'penalty': ['l2'],\n",
    "    'C': [100, 1000], # 0.001, 0.01, 0.1, 1, 10, \n",
    "    'fit_intercept': [True], # False\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 2, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "param_grid_gb = {\n",
    "    'loss': ['log_loss'],\n",
    "    'learning_rate': [0.02], # 0.1, 0.5\n",
    "    'n_estimators': [300], # 100, 200 \n",
    "    'criterion': ['squared_error'],\n",
    "    'max_depth': [5], # None, 2, 10\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50a12efa",
   "metadata": {},
   "source": [
    "## Pipeline for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfcad47a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T10:55:59.000812Z",
     "iopub.status.busy": "2023-03-31T10:55:59.000181Z",
     "iopub.status.idle": "2023-03-31T10:56:05.547158Z",
     "shell.execute_reply": "2023-03-31T10:56:05.545355Z"
    },
    "papermill": {
     "duration": 6.556451,
     "end_time": "2023-03-31T10:56:05.553525",
     "exception": false,
     "start_time": "2023-03-31T10:55:58.997074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Select predictors, apply pre-processing steps, define the model, and fit the model to the training data.\n",
    "sub = [\"X1\", \"X2\", \"X6\", \"X11\", \"X12\"]\n",
    "X_train_sub  = X_train[sub]\n",
    "X_test_sub = X_test[sub]\n",
    "\n",
    "\"\"\"\n",
    "- If “mean”, then replace missing values using the mean along each column. Can only be used with numeric data.\n",
    "- If “median”, then replace missing values using the median along each column. Can only be used with numeric data.\n",
    "- If “most_frequent”, then replace missing using the most frequent value along each column. Can be used with strings or numeric data.\n",
    "    If there is more than one such value, only the smallest is returned.\n",
    "- If “constant”, then replace missing values with fill_value. Can be used with strings or numeric data.\n",
    "\"\"\"\n",
    "\n",
    "numeric_features = sub\n",
    "numeric_features.remove(\"X12\")\n",
    "numeric_features.remove(\"X11\")\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')), # mean, median, most_frequent\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['X11' if \"X11\" in sub else None] + ['X12' if \"X12\" in sub else None]\n",
    "categorical_features.remove(None)\n",
    "categorical_features.remove(None)\n",
    "X_train_sub = X_train_sub.astype({'X11':'category', 'X12':'category'})\n",
    "X_test_sub = X_test_sub.astype({'X11':'category', 'X12':'category'})\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # obligatoire\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first'))]) #Same as pd.get_dummies \n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "grids = {'KNN': GridSearchCV(KNeighborsClassifier(), param_grid_knn, scoring='neg_log_loss', **default_grid_params),\n",
    "        'Logistic Regression': GridSearchCV(LogisticRegression(), param_grid_lr, scoring='neg_log_loss', **default_grid_params),\n",
    "        'Random Forest': GridSearchCV(RandomForestClassifier(), param_grid_rf, scoring='neg_log_loss', **default_grid_params),\n",
    "        'Gradient Boosting': GridSearchCV(GradientBoostingClassifier(), param_grid_gb, scoring='neg_log_loss', **default_grid_params)\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "367d357b",
   "metadata": {},
   "source": [
    "## Fit all models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f45f54ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in grids.items():\n",
    "    model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', model)])\n",
    "    model.fit(X_train_sub, y_train.values.ravel())\n",
    "    grids[model_name] = model\n",
    "    print(f'{model_name} fitted')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e748e8ba",
   "metadata": {},
   "source": [
    "## Compute the predicted probability for each class on the training set and evaluate on the log-loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3643bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Log-loss on training set...\")\n",
    "log_loss_test = {}\n",
    "for model_name, model in grids.items():\n",
    "    pred_prob_train = pd.DataFrame(model.predict_proba(X_test_sub))\n",
    "    loss = log_loss(y_test, pred_prob_train)\n",
    "    print(f'{model_name}: {loss}')\n",
    "    log_loss_test[model_name] = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44610bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is Random Forest with a log-loss of 0.4532672388265402\n"
     ]
    }
   ],
   "source": [
    "# Best model compare by the log-loss on the test set.\n",
    "best_model = min(log_loss_test, key=log_loss_test.get)\n",
    "print(f'Best model is {best_model} with a log-loss of {log_loss_test[best_model]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af771571",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b56362c2",
   "metadata": {},
   "source": [
    "## Predict on the test predictors, and save the probabilities to a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "016a0932",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_test = pd.DataFrame(grids[best_model].predict_proba(X_test_real))\n",
    "pred_prob_test.rename(columns = {0: 'Y_1', 1: 'Y_2', 2: 'Y_3', 3: 'Y_4', 4: 'Y_5', 5:'Y_6', 6:'Y_7'}, inplace = True)\n",
    "idx = pred_prob_test.index\n",
    "pred_prob_test.insert(0, 'id', idx)\n",
    "pred_prob_test.to_csv(\"Group13.csv\", index=False)\n",
    "pred_prob_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dd4527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.826631,
   "end_time": "2023-03-31T10:56:08.679002",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-31T10:55:47.852371",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
