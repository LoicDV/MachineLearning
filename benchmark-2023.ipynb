{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "00ffee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, ConfusionMatrixDisplay, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d450abe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T10:55:58.780575Z",
     "iopub.status.busy": "2023-03-31T10:55:58.780166Z",
     "iopub.status.idle": "2023-03-31T10:55:58.992240Z",
     "shell.execute_reply": "2023-03-31T10:55:58.991225Z"
    },
    "papermill": {
     "duration": 0.219589,
     "end_time": "2023-03-31T10:55:58.994949",
     "exception": false,
     "start_time": "2023-03-31T10:55:58.775360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load training dataset, remove missing values in Y, create X and Y matrices.\n",
    "\n",
    "df_train = pd.read_csv('data/train.csv')\n",
    "\n",
    "df_train.dropna(subset=['Y'], inplace=True)\n",
    "\n",
    "X = df_train.drop('Y', axis = 1)\n",
    "y = df_train[['Y']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.8, test_size=0.2, shuffle=True, random_state=0\n",
    ")\n",
    "\n",
    "#Load test predictors\n",
    "\n",
    "X_test_real = pd.read_csv('data/Xtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7e45e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_grid_params = dict(cv=5, n_jobs=4, verbose=1, scoring='neg_log_loss')\n",
    "\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [100], # 3, 5, 7, 10, 14, 20, 50, 100, 200, 500, 1000\n",
    "    'weights': ['distance'], # 'uniform'\n",
    "    'p': [1], # 2\n",
    "}\n",
    "\n",
    "param_grid_lr = {\n",
    "    'penalty': ['l2'],\n",
    "    'C': [100, 1000], # 0.001, 0.01, 0.1, 1, 10, \n",
    "    'fit_intercept': [True], # False\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [ 1000, 2000, 4000], # 1000\n",
    "    'criterion' : [\"log_loss\"],\n",
    "    \"max_depth\" : [ 50, 100, 300, 500], # 100\n",
    "    'min_samples_split' : [2, 5], # 2\n",
    "    'min_samples_leaf' : [1, 2] # 1\n",
    "}\n",
    "\n",
    "param_grid_gb = {\n",
    "    'loss': ['log_loss'],\n",
    "    'learning_rate': [0.02, 0.1, 0.5], # 0.1, 0.5\n",
    "    'n_estimators': [300, 500, 750, 1000], # 100, 200 \n",
    "    'criterion': ['squared_error'],\n",
    "    'max_depth': [None, 2, 5, 10], # None, 2, 10\n",
    "    'validation_fraction' : [0.2],\n",
    "    'n_iter_no_change' : [5],\n",
    "    'tol' : [1e-4]\n",
    "}\n",
    "\n",
    "param_grid_hgb = {\n",
    "    'loss': ['log_loss'],\n",
    "    'learning_rate': [0.02, 0.1, 0.5],\n",
    "    'max_iter': [300, 500, 750, 1000],\n",
    "    'max_leaf_nodes': [None, 2, 5, 10],\n",
    "    'min_samples_leaf': [20, 50, 100],\n",
    "    'l2_regularization': [0, 0.1, 0.5, 1],\n",
    "    'validation_fraction' : [0.2],\n",
    "    'n_iter_no_change' : [5],\n",
    "    'tol' : [1e-4]\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50a12efa",
   "metadata": {},
   "source": [
    "## Pipeline for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a538f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sub, X_train_sub, X_test_sub):\n",
    "    numeric_features = copy.copy(sub)\n",
    "    categorical_features = list()\n",
    "    if \"X11\" in sub:\n",
    "        numeric_features.remove(\"X11\")\n",
    "        categorical_features.append(\"X11\")\n",
    "    if \"X12\" in sub:\n",
    "        numeric_features.remove(\"X12\")\n",
    "        categorical_features.append(\"X12\")\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')), # mean, median, most_frequent\n",
    "        ('scaler', StandardScaler())], verbose=True)\n",
    "\n",
    "    if len(categorical_features) > 1:\n",
    "        X_train_sub = X_train_sub.astype({'X11':'category', 'X12':'category'})\n",
    "        X_test_sub = X_test_sub.astype({'X11':'category', 'X12':'category'})\n",
    "    elif len(categorical_features) == 1:\n",
    "        if categorical_features[0] == \"X11\":\n",
    "            X_train_sub = X_train_sub.astype({'X11':'category'})\n",
    "            X_test_sub = X_test_sub.astype({'X11':'category'})\n",
    "        else:\n",
    "            X_train_sub = X_train_sub.astype({'X12':'category'})\n",
    "            X_test_sub = X_test_sub.astype({'X12':'category'})\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')), # obligatoire\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first'))], verbose=True) #Same as pd.get_dummies \n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)])\n",
    "    \n",
    "    return preprocessor, X_train_sub, X_test_sub"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46d02352",
   "metadata": {},
   "source": [
    "### Permet de vérifier si les colonnes trouvés par la correlation sont bien les mêmes que celles trouvés par combinaison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcad47a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-31T10:55:59.000812Z",
     "iopub.status.busy": "2023-03-31T10:55:59.000181Z",
     "iopub.status.idle": "2023-03-31T10:56:05.547158Z",
     "shell.execute_reply": "2023-03-31T10:56:05.545355Z"
    },
    "papermill": {
     "duration": 6.556451,
     "end_time": "2023-03-31T10:56:05.553525",
     "exception": false,
     "start_time": "2023-03-31T10:55:58.997074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Select predictors, apply pre-processing steps, define the model, and fit the model to the training data.\n",
    "dict = {}\n",
    "for i in range(1, 13):\n",
    "    liste = list(itertools.combinations(X_train.columns, i))\n",
    "    for sub in liste:\n",
    "        sub = list(sub)\n",
    "        X_train_sub  = X_train[sub]\n",
    "        X_test_sub = X_test[sub]\n",
    "\n",
    "        preprocessor, X_train_sub, X_test_sub, numeric_transformer, numeric_features, categorical_transformer, categorical_features = preprocessing(sub, X_train_sub, X_test_sub)\n",
    "\n",
    "        grids = {'KNN': GridSearchCV(KNeighborsClassifier(), param_grid_knn, **default_grid_params)}\n",
    "\n",
    "        model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', grids[\"KNN\"])])\n",
    "        model.fit(X_train_sub, y_train.values.ravel())\n",
    "        grids[\"KNN\"] = model\n",
    "        print(\"KNN fitted\")\n",
    "        pred_prob_train = pd.DataFrame(model.predict_proba(X_test_sub))\n",
    "        loss = log_loss(y_test, pred_prob_train)\n",
    "        print(f'KNN : {loss} for {sub}')\n",
    "        dict[(i, tuple(sub))] = loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ee7c32a",
   "metadata": {},
   "source": [
    "### Code générique pour construire notre model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "367d357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit all models \n",
    "sub = [\"X1\", \"X6\", \"X10\", \"X11\", \"X12\"]\n",
    "X_train_sub  = X_train[sub]\n",
    "X_test_sub = X_test[sub]\n",
    "\n",
    "preprocessor, X_train_sub, X_test_sub = preprocessing(sub, X_train_sub, X_test_sub)\n",
    "\n",
    "grids = {#'KNN': GridSearchCV(KNeighborsClassifier(), param_grid_knn, **default_grid_params),\n",
    "        #'Logistic Regression': GridSearchCV(LogisticRegression(max_iter=1000), param_grid_lr, **default_grid_params),\n",
    "        #'Random Forest': GridSearchCV(RandomForestClassifier(), param_grid_rf, **default_grid_params),\n",
    "        'Gradient Boosting': GridSearchCV(HistGradientBoostingClassifier(), param_grid_hgb, **default_grid_params)\n",
    "        }\n",
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return np.asarray(X.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f45f54ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 2) Processing imputer, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ........... (step 1 of 2) Processing imputer, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing onehot, total=   0.0s\n",
      "[Pipeline] ...... (step 1 of 3) Processing preprocessor, total=   0.1s\n",
      "[Pipeline] .......... (step 2 of 3) Processing to_dense, total=   0.0s\n",
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n",
      "[Pipeline] ....... (step 3 of 3) Processing classifier, total=337.6min\n",
      "Gradient Boosting fitted\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in grids.items():\n",
    "    model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                            ('to_dense', DenseTransformer()),\n",
    "                            ('classifier', model)], verbose=True)\n",
    "    model.fit(X_train_sub, y_train.values.ravel())\n",
    "    grids[model_name] = model\n",
    "    print(f'{model_name} fitted')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e748e8ba",
   "metadata": {},
   "source": [
    "## Compute the predicted probability for each class on the training set and evaluate on the log-loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ca3643bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-loss on training set...\n",
      "Gradient Boosting: 0.36307570127102506\n"
     ]
    }
   ],
   "source": [
    "print(\"Log-loss on training set...\")\n",
    "log_loss_test = {}\n",
    "for model_name, model in grids.items():\n",
    "    pred_prob_train = pd.DataFrame(model.predict_proba(X_test_sub))\n",
    "    loss = log_loss(y_test, pred_prob_train)\n",
    "    print(f'{model_name}: {loss}')\n",
    "    log_loss_test[model_name] = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "44610bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is Gradient Boosting with a log-loss of 0.36307570127102506\n"
     ]
    }
   ],
   "source": [
    "# Best model compare by the log-loss on the test set.\n",
    "best_model = min(log_loss_test, key=log_loss_test.get)\n",
    "print(f'Best model is {best_model} with a log-loss of {log_loss_test[best_model]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b56362c2",
   "metadata": {},
   "source": [
    "## Predict on the test predictors, and save the probabilities to a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "016a0932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Y_1</th>\n",
       "      <th>Y_2</th>\n",
       "      <th>Y_3</th>\n",
       "      <th>Y_4</th>\n",
       "      <th>Y_5</th>\n",
       "      <th>Y_6</th>\n",
       "      <th>Y_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.053425</td>\n",
       "      <td>0.945265</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.996951</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.540724</td>\n",
       "      <td>0.457770</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.026869</td>\n",
       "      <td>0.969226</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.119275</td>\n",
       "      <td>0.864733</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.014536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       Y_1       Y_2       Y_3       Y_4       Y_5       Y_6       Y_7\n",
       "0   0  0.053425  0.945265  0.000402  0.000037  0.000322  0.000325  0.000224\n",
       "1   1  0.001980  0.996951  0.000510  0.000012  0.000323  0.000131  0.000092\n",
       "2   2  0.540724  0.457770  0.000483  0.000070  0.000195  0.000271  0.000489\n",
       "3   3  0.026869  0.969226  0.000582  0.000031  0.002206  0.000931  0.000154\n",
       "4   4  0.119275  0.864733  0.000690  0.000100  0.000279  0.000387  0.014536"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob_test = pd.DataFrame(grids[best_model].predict_proba(X_test_real))\n",
    "pred_prob_test.rename(columns = {0: 'Y_1', 1: 'Y_2', 2: 'Y_3', 3: 'Y_4', 4: 'Y_5', 5:'Y_6', 6:'Y_7'}, inplace = True)\n",
    "idx = pred_prob_test.index\n",
    "pred_prob_test.insert(0, 'id', idx)\n",
    "pred_prob_test.to_csv(\"Group13.csv\", index=False)\n",
    "pred_prob_test.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e25b73df",
   "metadata": {},
   "source": [
    "https://askcodez.com/comment-ameliorer-randomforest-la-performance.html\n",
    "\n",
    "https://stats.stackexchange.com/questions/53240/practical-questions-on-tuning-random-forests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.826631,
   "end_time": "2023-03-31T10:56:08.679002",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-31T10:55:47.852371",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
